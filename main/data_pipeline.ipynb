{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"KlNxPuc1dMZa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701365109305,"user_tz":-420,"elapsed":18792,"user":{"displayName":"Ha Nguyen","userId":"00133018006977627660"}},"outputId":"a607d97f-29d3-41a8-c5c0-0799a4a1e53e"},"id":"KlNxPuc1dMZa","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","id":"a3ecf773-f2ee-4aad-9a66-e57398c7e67d","metadata":{"tags":[],"id":"a3ecf773-f2ee-4aad-9a66-e57398c7e67d"},"source":["# Setup"]},{"cell_type":"code","execution_count":null,"id":"de8dc810-63eb-4348-b4f3-078f4b2e50f6","metadata":{"tags":[],"id":"de8dc810-63eb-4348-b4f3-078f4b2e50f6"},"outputs":[],"source":["import json\n","from pathlib import Path\n","from types import SimpleNamespace\n","\n","import pandas as pd\n","import tensorflow as tf\n","import tensorflow_datasets as tfds\n","from tensorflow import keras"]},{"cell_type":"code","execution_count":null,"id":"f798ba17-79a6-486c-97e0-b20b899258c6","metadata":{"tags":[],"id":"f798ba17-79a6-486c-97e0-b20b899258c6"},"outputs":[],"source":["gpus = tf.config.list_physical_devices(\"GPU\")\n","if gpus:\n","    try:\n","        # Currently, memory growth needs to be the same across GPUs\n","        for gpu in gpus:\n","            tf.config.experimental.set_memory_growth(gpu, True)\n","        logical_gpus = tf.config.list_logical_devices(\"GPU\")\n","        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n","    except RuntimeError as e:\n","        # Memory growth must be set before GPUs have been initialized\n","        print(e)\n","\n","del gpus"]},{"cell_type":"markdown","id":"d8539ace-0125-40d0-baa3-4d3684b47d1c","metadata":{"id":"d8539ace-0125-40d0-baa3-4d3684b47d1c"},"source":["# Build a universal one hot encoder that encodes cross-dataset category and ingredients"]},{"cell_type":"code","execution_count":null,"id":"09725b24-85d1-4ecb-9b34-3894255a1c97","metadata":{"tags":[],"id":"09725b24-85d1-4ecb-9b34-3894255a1c97"},"outputs":[],"source":["class OneHotEncoder:\n","    def __init__(self, all_category_list, all_ingredient_list):\n","        self.all_food_categories = all_category_list\n","        self.all_food_categories.sort()\n","        self.all_food_categories_integer_encoded = (\n","            self.__encode_categories_to_integers()\n","        )\n","        self.all_ingredients = all_ingredient_list\n","        self.all_ingredients.sort()\n","        self.all_ingredients_integer_encoded = self.__encode_ingredients_to_integers()\n","\n","    def get_category_one_hot_encoding(self, category_name):\n","        index = self.all_food_categories_integer_encoded[category_name]\n","        assert index is not None, f\"{category_name} does not have an integer mapping\"\n","        num_classes = len(self.all_food_categories)\n","        return keras.utils.to_categorical(index, num_classes, dtype=\"uint8\")\n","\n","    def get_ingredients_one_hot_encoding(self, ingredient_list):\n","        ingredient_list = list(\n","            map(lambda x: self.__transform_ingredient_to_integer(x), ingredient_list)\n","        )\n","        multi_one_hot_layer = tf.keras.layers.CategoryEncoding(\n","            num_tokens=len(self.all_ingredients), output_mode=\"multi_hot\"\n","        )\n","        return tf.cast(multi_one_hot_layer(ingredient_list), dtype=tf.uint8)\n","\n","    def __transform_ingredient_to_integer(self, ingredient_name):\n","        index = self.all_ingredients_integer_encoded[ingredient_name]\n","        assert index is not None, f\"{ingredient_name} does not have an integer mapping\"\n","        return index\n","\n","    def __encode_categories_to_integers(self):\n","        return {\n","            category_name: index\n","            for index, category_name in enumerate(self.all_food_categories)\n","        }\n","\n","    def __encode_ingredients_to_integers(self):\n","        return {\n","            ingredient_name: index\n","            for index, ingredient_name in enumerate(self.all_ingredients)\n","        }"]},{"cell_type":"markdown","id":"c1c256db-8606-4a26-aa9a-d78bae31270b","metadata":{"id":"c1c256db-8606-4a26-aa9a-d78bae31270b"},"source":["# Build dataset loaders for each dataset"]},{"cell_type":"code","execution_count":null,"id":"ef193835-66bf-4ded-b62c-d0d286157b35","metadata":{"tags":[],"id":"ef193835-66bf-4ded-b62c-d0d286157b35"},"outputs":[],"source":["class DatasetLoader:\n","    def __init__(self, image_dir, metadata_dir, dataset_name):\n","        self.image_dir = Path(image_dir)\n","        self.metadata_dir = Path(metadata_dir)\n","        self.name = dataset_name\n","        self.metadata = self.load_metadata(\n","            self.metadata_dir / (\"{dataset}_metadata.csv\".format(dataset=dataset_name))\n","        )\n","        # Default : all_files = metadata, since metadata consists of records of all files\n","        self.all_files = self.metadata.copy()\n","        self.all_categories = self.extract_all_categories()\n","        self.all_ingredients = self.extract_all_ingredients()\n","\n","    def load_image_to_arr(self, path):\n","        image = tf.keras.preprocessing.image.load_img(path)\n","        img_tensor = tf.keras.preprocessing.image.img_to_array(image, dtype=\"uint8\")\n","        img_tensor = tf.image.resize(img_tensor, (224, 224))\n","        return tf.cast(img_tensor, tf.uint8)\n","\n","    def load_metadata(self, path):\n","        metadata = pd.read_csv(path, sep=\"\\t\")\n","        new_metadata = metadata.copy()\n","        new_metadata[\"dataset_name\"] = self.name\n","        return new_metadata\n","\n","    def extract_all_categories(self):\n","        return self.metadata[\"Category\"].unique().tolist()\n","\n","    def extract_all_ingredients(self):\n","        unique_ingredients = set()\n","        for ingredient_list in self.metadata[\"Ingredients\"]:\n","            ingredient_list = ingredient_list.split(\",\")\n","            unique_ingredients.update(ingredient_list)\n","        return [*unique_ingredients]\n","\n","    def extract_file_pointers(self):\n","        dataset_name_col = self.all_files[\"dataset_name\"]\n","        index_col = self.all_files.index\n","        return pd.DataFrame(\n","            {\"metadata_index\": index_col, \"dataset_name\": dataset_name_col}\n","        )\n","\n","    def get_tensors(self, index):\n","        img_dir = self.image_dir\n","        row = self.all_files.loc[index]\n","        img_path = img_dir / row[\"Category\"] / row[\"ID/File Name\"]\n","        img_tensor = self.load_image_to_arr(img_path)\n","        if img_path.suffix == \".jpeg\" or img_path.suffix == \".jpg\":\n","            img_tensor = tf.io.encode_jpeg(img_tensor, format=\"rgb\")\n","        elif img_path.suffix == \".png\":\n","            img_tensor = tf.io.encode_png(img_tensor)\n","        else:\n","            assert False, \"Invalid image format present\"\n","        calorie_tensor = row[\"Calorie(kcal)\"]\n","        carbs_tensor = row[\"Carbohydrate(g)\"]\n","        protein_tensor = row[\"Protein(g)\"]\n","        fat_tensor = row[\"Fat(g)\"]\n","        return img_tensor, {\n","            \"category_output\": tf.constant(row[\"Category\"]),\n","            \"calorie_output\": tf.constant(calorie_tensor),\n","            \"carbs_output\": tf.constant(carbs_tensor),\n","            \"protein_output\": tf.constant(protein_tensor),\n","            \"fat_output\": tf.constant(fat_tensor),\n","            \"ingredients_output\": tf.constant(row[\"Ingredients\"]),\n","        }\n","\n","    def flatten_tensors(self, tensor):\n","        result = []\n","        img_data = tensor[0].numpy()\n","        others_data = [value.numpy() for key, value in tensor[1].items()]\n","        result.append(img_data)\n","        result.extend(others_data)\n","        return result\n","\n","    def __len__(self):\n","        return len(self.metadata)"]},{"cell_type":"code","execution_count":null,"id":"9f876af8-e890-447a-8d1c-3f07969052ba","metadata":{"tags":[],"id":"9f876af8-e890-447a-8d1c-3f07969052ba"},"outputs":[],"source":["class Recipes5k(DatasetLoader):\n","    def __init__(self, image_dir, metadata_dir):\n","        super().__init__(image_dir, metadata_dir, \"recipes5k\")"]},{"cell_type":"code","execution_count":null,"id":"b0ff5ec7-bf8c-472f-9f46-10c3042dc391","metadata":{"tags":[],"id":"b0ff5ec7-bf8c-472f-9f46-10c3042dc391"},"outputs":[],"source":["class Food101(DatasetLoader):\n","    def __init__(self, image_dir, metadata_dir):\n","        super().__init__(image_dir, metadata_dir, \"food101\")"]},{"cell_type":"markdown","id":"6fb374be-7cf9-4042-be86-473a60a8f553","metadata":{"id":"6fb374be-7cf9-4042-be86-473a60a8f553"},"source":["# Initializing one hot encoder\n","\n","*   Mục danh sách\n","*   Mục danh sách\n","\n"]},{"cell_type":"code","execution_count":null,"id":"4cc3c605-ac9d-423b-ae0d-154d1641cd39","metadata":{"tags":[],"id":"4cc3c605-ac9d-423b-ae0d-154d1641cd39"},"outputs":[],"source":["# Get all the categories and ingredients from all datasets\n","\n","# Initialize dataset loader without one-hot encoder to get all unique category and ingredients from each dataset\n","RECIPES5K = Recipes5k(\n","    image_dir=\"./drive/MyDrive/FoodCaloModel/Food Datasets/final-dataset/images\",\n","    metadata_dir=\"./drive/MyDrive/FoodCaloModel/Food Datasets/final-dataset/metadata\",\n",")\n","FOOD101 = Food101(\n","    image_dir=\"./drive/MyDrive/FoodCaloModel/Food Datasets/final-dataset/food101-images\",\n","    metadata_dir=\"./drive/MyDrive/FoodCaloModel/Food Datasets/final-dataset/metadata\",\n",")\n","\n","DATASETS = [RECIPES5K, FOOD101]\n","DATASETS_NAME = [x.name for x in DATASETS]\n","\n","\n","def create_one_hot_encoder(datasets):\n","    all_categories = []\n","    all_ingredients = []\n","    for x in datasets:\n","        all_categories.extend(x.all_categories)\n","        all_ingredients.extend(x.all_ingredients)\n","    all_categories = set(all_categories)\n","    all_ingredients = set(all_ingredients)\n","    return OneHotEncoder([*all_categories], [*all_ingredients])"]},{"cell_type":"code","execution_count":null,"id":"d08bb542-3d60-4033-8216-8a316cdeebf4","metadata":{"tags":[],"id":"d08bb542-3d60-4033-8216-8a316cdeebf4"},"outputs":[],"source":["ONE_HOT_ENCODER = create_one_hot_encoder(DATASETS)"]},{"cell_type":"markdown","id":"270ad655-5f17-43b3-b75e-e71aa19c9f88","metadata":{"id":"270ad655-5f17-43b3-b75e-e71aa19c9f88"},"source":["# Building data pipeline that streams the file index and dataset index"]},{"cell_type":"code","execution_count":null,"id":"fe84dc4a-1fb4-48a1-9a2c-29b29ebbfaa4","metadata":{"tags":[],"id":"fe84dc4a-1fb4-48a1-9a2c-29b29ebbfaa4"},"outputs":[],"source":["def get_file_data(index, dataset_index):\n","    target_dataset = DATASETS[dataset_index]\n","    return target_dataset.flatten_tensors(target_dataset.get_tensors(index))\n","\n","\n","def build_data_pipeline(datasets, sample_size=None):\n","    if sample_size is None:\n","        sample_size = [1.0] * len(datasets)\n","    assert len(sample_size) == len(\n","        datasets\n","    ), \"Illegal array of sample sizes provided. Number of sample size does not match number of datasets\"\n","    file_pointers = [\n","        x.extract_file_pointers().sample(frac=s, random_state=999)\n","        for x, s in zip(datasets, sample_size)\n","    ]\n","    all_file_pointers = pd.concat(file_pointers).sample(frac=1, random_state=999)\n","    print(f\"Total samples : {len(all_file_pointers)}\")\n","\n","    all_file_pointers[\"dataset_name\"] = all_file_pointers[\"dataset_name\"].apply(\n","        lambda x: DATASETS_NAME.index(x)\n","    )\n","\n","    final_dataset = tf.data.Dataset.from_tensor_slices(\n","        (\n","            all_file_pointers[\"metadata_index\"].tolist(),\n","            all_file_pointers[\"dataset_name\"].tolist(),\n","        )\n","    )\n","    return final_dataset"]},{"cell_type":"code","execution_count":null,"id":"e3f30aff-2b6e-48f9-9e2e-977224538d11","metadata":{"tags":[],"id":"e3f30aff-2b6e-48f9-9e2e-977224538d11","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701365114286,"user_tz":-420,"elapsed":10,"user":{"displayName":"Ha Nguyen","userId":"00133018006977627660"}},"outputId":"ee5cc021-05d8-410e-8b1a-e29202356ae2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Total samples : 1139\n","Total samples : 12000\n"]}],"source":["recipes5k_dataset = build_data_pipeline([RECIPES5K])\n","food101_dataset = build_data_pipeline([FOOD101])"]},{"cell_type":"code","execution_count":null,"id":"2910985d-06c6-47bb-979d-bedb7b7d1a1f","metadata":{"tags":[],"id":"2910985d-06c6-47bb-979d-bedb7b7d1a1f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701365114286,"user_tz":-420,"elapsed":8,"user":{"displayName":"Ha Nguyen","userId":"00133018006977627660"}},"outputId":"6e0b0447-8957-4890-dffa-a3af6ae8f4a7"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(<tf.Tensor: shape=(), dtype=int32, numpy=732>,\n","  <tf.Tensor: shape=(), dtype=int32, numpy=0>),\n"," (<tf.Tensor: shape=(), dtype=int32, numpy=835>,\n","  <tf.Tensor: shape=(), dtype=int32, numpy=0>)]"]},"metadata":{},"execution_count":12}],"source":["list(recipes5k_dataset.take(2))"]},{"cell_type":"markdown","id":"95f3f017-46fc-4bdc-8eda-8d7aa69b4097","metadata":{"id":"95f3f017-46fc-4bdc-8eda-8d7aa69b4097"},"source":["## Serializing Data Pipeline to TFRecord with TFDS Features"]},{"cell_type":"code","execution_count":null,"id":"d8175168-8a97-4ea6-a457-279dbf582c91","metadata":{"id":"d8175168-8a97-4ea6-a457-279dbf582c91","executionInfo":{"status":"ok","timestamp":1701365114286,"user_tz":-420,"elapsed":6,"user":{"displayName":"Ha Nguyen","userId":"00133018006977627660"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"91e50799-b4d5-4ddc-9164-3a64067dc91f"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:You use TensorFlow DType <dtype: 'string'> in tfds.features This will soon be deprecated in favor of NumPy DTypes. In the meantime it was converted to object.\n","WARNING:absl:You use TensorFlow DType <dtype: 'float32'> in tfds.features This will soon be deprecated in favor of NumPy DTypes. In the meantime it was converted to float32.\n"]}],"source":["FEATURE_DICTIONARY = tfds.features.FeaturesDict(\n","    {\n","        \"image_raw\": tfds.features.Image(\n","            shape=(224, 224, 3), doc=\"Raw bytes of food images encoded with tf.io\"\n","        ),\n","        \"category\": tfds.features.Scalar(dtype=tf.string, doc=\"Category label\"),\n","        \"calorie\": tfds.features.Scalar(\n","            dtype=tf.float32, doc=\"Calorie of the food per gram\"\n","        ),\n","        \"carbs\": tfds.features.Scalar(\n","            dtype=tf.float32, doc=\"Carbs of the food per gram\"\n","        ),\n","        \"protein\": tfds.features.Scalar(\n","            dtype=tf.float32, doc=\"Protein of the food per gram\"\n","        ),\n","        \"fat\": tfds.features.Scalar(dtype=tf.float32, doc=\"Fat of the food per gram\"),\n","        \"ingredients\": tfds.features.Scalar(\n","            dtype=tf.string, doc=\"Ingredients of food separated with comma\"\n","        ),\n","    }\n",")"]},{"cell_type":"markdown","id":"eb2330f2-ee56-40d7-9404-a4025452bbcf","metadata":{"id":"eb2330f2-ee56-40d7-9404-a4025452bbcf"},"source":["### Shard and write to TFRecord file"]},{"cell_type":"code","execution_count":null,"id":"5224e67b-b845-4493-9eee-1a39633d31a2","metadata":{"id":"5224e67b-b845-4493-9eee-1a39633d31a2"},"outputs":[],"source":["def shard_and_write(dataset, num_shards, path, dataset_name):\n","    path = Path(path)\n","    if not path.exists():\n","        path.mkdir()\n","\n","    sharded_template_generator = tfds.core.ShardedFileTemplate(\n","        data_dir=path.as_posix(),\n","        template=\"{DATASET}-{SPLIT}-{SHARD_X_OF_Y}.{FILEFORMAT}\",\n","        dataset_name=dataset_name,\n","        filetype_suffix=\"tfrecord\",\n","        split=\"train\",\n","    )\n","    shard_length = []\n","    sharded_filepaths = sharded_template_generator.sharded_filepaths(num_shards)\n","    for i in range(num_shards):\n","        current_shard = dataset.shard(num_shards, i)\n","        with tf.io.TFRecordWriter(sharded_filepaths[i].as_posix()) as writer:\n","            length = 0\n","            for record in current_shard.as_numpy_iterator():\n","                data = get_file_data(record[0], record[1])\n","                example = {\n","                    \"image_raw\": data[0],\n","                    \"category\": data[1],\n","                    \"calorie\": data[2],\n","                    \"carbs\": data[3],\n","                    \"protein\": data[4],\n","                    \"fat\": data[5],\n","                    \"ingredients\": data[6],\n","                }\n","                example_bytes = FEATURE_DICTIONARY.serialize_example(example)\n","                writer.write(example_bytes)\n","                length += 1\n","            shard_length.append(length)\n","    split_info = [\n","        tfds.core.SplitInfo(\n","            name=\"train\",\n","            shard_lengths=shard_length,\n","            num_bytes=0,\n","            filename_template=sharded_template_generator,\n","        )\n","    ]\n","    tfds.folder_dataset.write_metadata(\n","        data_dir=path.as_posix(),\n","        features=FEATURE_DICTIONARY,\n","        filename_template=\"{DATASET}-{SPLIT}-{SHARD_X_OF_Y}.{FILEFORMAT}\",\n","        split_infos=split_info,\n","    )\n","    return shard_length\n"]},{"cell_type":"code","source":["shard_length2 = shard_and_write(\n","    food101_dataset,\n","    10,\n","    f\"./drive/MyDrive/FoodCaloModel/Food Datasets/final-dataset/tfrecord/{FOOD101.name}/1.1.0\",\n","    FOOD101.name,\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dFIDqfuFt_Ya","executionInfo":{"status":"ok","timestamp":1701368189356,"user_tz":-420,"elapsed":3075073,"user":{"displayName":"Ha Nguyen","userId":"00133018006977627660"}},"outputId":"279b161c-5d0f-4c60-89ec-c6959420143d"},"id":"dFIDqfuFt_Ya","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Metadata written. Testing by reading first example. Set check_data=False to skip.\n"]}]},{"cell_type":"markdown","id":"7d605606-2412-45d8-a609-1818a9db999e","metadata":{"id":"7d605606-2412-45d8-a609-1818a9db999e"},"source":["# Exported"]},{"cell_type":"code","execution_count":null,"id":"115d8ff3-8289-46a2-b34c-8c83e8d54cec","metadata":{"id":"115d8ff3-8289-46a2-b34c-8c83e8d54cec"},"outputs":[],"source":["EXPORTED = {\"datasets\": DATASETS, \"one_hot_encoder\": ONE_HOT_ENCODER}"]},{"cell_type":"code","execution_count":null,"id":"efd129b6-b1b5-489f-84f6-18a10968bd21","metadata":{"id":"efd129b6-b1b5-489f-84f6-18a10968bd21"},"outputs":[],"source":["EXPORTED = SimpleNamespace(**EXPORTED)"]},{"cell_type":"markdown","id":"b64d4ec8-2e89-486f-a010-943e7ad2bbaa","metadata":{"id":"b64d4ec8-2e89-486f-a010-943e7ad2bbaa"},"source":["## Export Encoded Categories and Ingredients for Decoding"]},{"cell_type":"code","execution_count":null,"id":"207fa0a3-5c91-4898-9dfe-9d68b6eeee07","metadata":{"tags":[],"id":"207fa0a3-5c91-4898-9dfe-9d68b6eeee07"},"outputs":[],"source":["json.dump(\n","    ONE_HOT_ENCODER.all_food_categories_integer_encoded,\n","    open(\"./encoded_food_categories.json\", \"w\"),\n",")"]},{"cell_type":"code","execution_count":null,"id":"1a528076-317c-4502-8d54-943a69f8ef4b","metadata":{"id":"1a528076-317c-4502-8d54-943a69f8ef4b"},"outputs":[],"source":["json.dump(\n","    ONE_HOT_ENCODER.all_ingredients_integer_encoded,\n","    open(\"./encoded_ingredients.json\", \"w\"),\n",")"]},{"cell_type":"markdown","id":"62107dc2-f723-40ea-93df-a4aba5722e6f","metadata":{"id":"62107dc2-f723-40ea-93df-a4aba5722e6f"},"source":["# Data Statistics"]},{"cell_type":"markdown","id":"b47f66f8-15aa-4952-85d1-a6083a5ec336","metadata":{"id":"b47f66f8-15aa-4952-85d1-a6083a5ec336"},"source":["## Categories Statistics"]},{"cell_type":"code","execution_count":null,"id":"677c827d-1357-48fb-89bf-e794ad216c4e","metadata":{"id":"677c827d-1357-48fb-89bf-e794ad216c4e","executionInfo":{"status":"ok","timestamp":1701368189357,"user_tz":-420,"elapsed":14,"user":{"displayName":"Ha Nguyen","userId":"00133018006977627660"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9676e1f7-6772-42ab-d17b-84ffa789a728"},"outputs":[{"output_type":"stream","name":"stdout","text":["The total number of ingredients : 24\n"]}],"source":["print(f\"The total number of ingredients : {len(ONE_HOT_ENCODER.all_food_categories)}\")"]},{"cell_type":"code","execution_count":null,"id":"f94e841d-50aa-4bab-b473-311610d1fb14","metadata":{"id":"f94e841d-50aa-4bab-b473-311610d1fb14"},"outputs":[],"source":["df = pd.concat([RECIPES5K.metadata, FOOD101.metadata])"]},{"cell_type":"code","execution_count":null,"id":"36a7885f-054f-4ab4-8b9b-1c0ec935aef0","metadata":{"id":"36a7885f-054f-4ab4-8b9b-1c0ec935aef0"},"outputs":[],"source":["df_grouped_categories = df.groupby(\"Category\")"]},{"cell_type":"code","execution_count":null,"id":"8abb57ec-91eb-48b2-a8b9-755ac4115ecb","metadata":{"tags":[],"id":"8abb57ec-91eb-48b2-a8b9-755ac4115ecb","executionInfo":{"status":"ok","timestamp":1701368189358,"user_tz":-420,"elapsed":12,"user":{"displayName":"Ha Nguyen","userId":"00133018006977627660"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a8e57f2c-e7af-4a42-8734-938cf6bb5cbf"},"outputs":[{"output_type":"stream","name":"stdout","text":["The lowest number of images per category : 508\n","The highest number of images per category : 550\n","The average number of images per category : 547\n"]}],"source":["print(\n","    f\"The lowest number of images per category : {df_grouped_categories.size().min()}\"\n",")\n","print(\n","    f\"The highest number of images per category : {df_grouped_categories.size().max()}\"\n",")\n","total_imgs = df_grouped_categories.size().sum()\n","total_category = len(df_grouped_categories)\n","\n","print(f\"The average number of images per category : {total_imgs//total_category}\")"]},{"cell_type":"markdown","id":"03b4c810-077a-4b08-be17-84ffc3a75042","metadata":{"id":"03b4c810-077a-4b08-be17-84ffc3a75042"},"source":["## Ingredients Statistics"]},{"cell_type":"code","execution_count":null,"id":"d4c10755-28a1-465d-832d-5b94c08f6623","metadata":{"id":"d4c10755-28a1-465d-832d-5b94c08f6623","executionInfo":{"status":"ok","timestamp":1701368189358,"user_tz":-420,"elapsed":9,"user":{"displayName":"Ha Nguyen","userId":"00133018006977627660"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b0711841-6a38-4318-9f4f-4f306b6353d8"},"outputs":[{"output_type":"stream","name":"stdout","text":["The total number of ingredients : 501\n"]}],"source":["print(f\"The total number of ingredients : {len(ONE_HOT_ENCODER.all_ingredients)}\")"]},{"cell_type":"code","execution_count":null,"id":"e161435d-f7ee-4974-8083-7ae7fb13fcf4","metadata":{"id":"e161435d-f7ee-4974-8083-7ae7fb13fcf4","executionInfo":{"status":"ok","timestamp":1701368189358,"user_tz":-420,"elapsed":7,"user":{"displayName":"Ha Nguyen","userId":"00133018006977627660"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"7f7b47ae-6b93-4a85-9b93-6eb32812a4a7"},"outputs":[{"output_type":"stream","name":"stdout","text":["The average number of ingredients for each dish (recipes5k + food101) : 10\n"]}],"source":["average = 0\n","for ing in df[\"Ingredients\"]:\n","    count_ing = len(ing.split(\",\"))\n","    average += count_ing\n","average = average // len(df)\n","print(\n","    f\"The average number of ingredients for each dish (recipes5k + food101) : {average}\"\n",")"]},{"cell_type":"markdown","id":"c07aee62-b540-437e-8ce1-e4843d6a4e96","metadata":{"tags":[],"id":"c07aee62-b540-437e-8ce1-e4843d6a4e96"},"source":["# Testing"]}],"metadata":{"kernelspec":{"display_name":"PY38-TF28-GPU","language":"python","name":"py38-tf28-gpu"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"},"toc-autonumbering":true,"toc-showcode":false,"toc-showmarkdowntxt":false,"toc-showtags":true,"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}